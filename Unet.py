{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977163a6-fc43-469f-9d85-07871d38413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define U-Net model\n",
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = tf.keras.layers.Input(input_size)\n",
    "\n",
    "    # Contracting path\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Expansive path\n",
    "    u6 = tf.keras.layers.UpSampling2D((2, 2))(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.UpSampling2D((2, 2))(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = tf.keras.layers.UpSampling2D((2, 2))(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = tf.keras.layers.UpSampling2D((2, 2))(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1])\n",
    "    c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Custom loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "# Initialize and compile the model\n",
    "model = unet_model()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=dice_loss, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, image_paths, mask_paths, batch_size=8, image_size=(256, 256), n_channels=3, shuffle=True, augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        if self.augment:\n",
    "            self.image_datagen = ImageDataGenerator(\n",
    "                rotation_range=30,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.3,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "            self.mask_datagen = ImageDataGenerator(\n",
    "                rotation_range=30,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.3,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        image_paths_temp = [self.image_paths[k] for k in indexes]\n",
    "        mask_paths_temp = [self.mask_paths[k] for k in indexes]\n",
    "\n",
    "        X, y = self.__data_generation(image_paths_temp, mask_paths_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, image_paths_temp, mask_paths_temp):\n",
    "        X = np.empty((self.batch_size, *self.image_size, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.image_size, 1))\n",
    "\n",
    "        for i, (img_path, mask_path) in enumerate(zip(image_paths_temp, mask_paths_temp)):\n",
    "            img = load_img(img_path, target_size=self.image_size)\n",
    "            img = img_to_array(img) / 255.0\n",
    "\n",
    "            mask = load_img(mask_path, target_size=self.image_size, color_mode=\"grayscale\")\n",
    "            mask = img_to_array(mask) / 255.0\n",
    "\n",
    "            if self.augment:\n",
    "                seed = np.random.randint(1, 10000)\n",
    "                img = self.image_datagen.random_transform(img, seed=seed)\n",
    "                mask = self.mask_datagen.random_transform(mask, seed=seed)\n",
    "\n",
    "            X[i,] = img\n",
    "            y[i,] = mask\n",
    "\n",
    "        return X, y\n",
    "\n",
    "# Enter your dataset path here\n",
    "dataset_path = r'E:\\Study\\Thesis\\Personal\\1. Already Done\\57. Paper 2024\\8. (I) Data In Brief\\2. Dataset\\dataset\\FruitSeg30'  # <-- Specify your dataset path here\n",
    "\n",
    "# Check if the dataset path is correct\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise ValueError(f\"Dataset path does not exist: {dataset_path}\")\n",
    "\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "# Populate the lists with the image and mask paths\n",
    "for class_folder in os.listdir(dataset_path):\n",
    "    class_folder_path = os.path.join(dataset_path, class_folder)\n",
    "    if not os.path.isdir(class_folder_path):\n",
    "        continue\n",
    "    \n",
    "    images_path = os.path.join(class_folder_path, 'Images')\n",
    "    masks_path = os.path.join(class_folder_path, 'Mask')\n",
    "\n",
    "    if not os.path.exists(images_path):\n",
    "        print(f\"Images path does not exist: {images_path}\")\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(masks_path):\n",
    "        print(f\"Masks path does not exist: {masks_path}\")\n",
    "        continue\n",
    "\n",
    "    images = glob.glob(os.path.join(images_path, '*.jpg'))  # Adjusted to find .jpg files\n",
    "    masks = glob.glob(os.path.join(masks_path, '*.png'))  # Adjusted to find .png files\n",
    "\n",
    "    if len(images) == 0 or len(masks) == 0:\n",
    "        print(f\"No images or masks found in class folder: {class_folder}\")\n",
    "        continue\n",
    "\n",
    "    image_paths.extend(images)\n",
    "    mask_paths.extend(masks)\n",
    "\n",
    "print(f\"Total images found: {len(image_paths)}\")\n",
    "print(f\"Total masks found: {len(mask_paths)}\")\n",
    "\n",
    "if len(image_paths) == 0 or len(mask_paths) == 0:\n",
    "    raise ValueError(\"No images or masks found. Please check the dataset path and directory structure.\")\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_image_paths, val_image_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize data generators with augmentation for the training set\n",
    "train_gen = DataGenerator(train_image_paths, train_mask_paths, image_size=(256, 256), augment=True)\n",
    "val_gen = DataGenerator(val_image_paths, val_mask_paths, image_size=(256, 256))\n",
    "\n",
    "# Early stopping and model checkpoint\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_unet_model.h5', save_best_only=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=200, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Load the best model\n",
    "model = tf.keras.models.load_model('best_unet_model.h5', custom_objects={'dice_loss': dice_loss})\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1)\n",
    "\n",
    "def display_predictions(image_paths, mask_paths, model, num_samples=50, output_dir=r'E:\\Study\\Thesis\\Personal\\1. Already Done\\57. Paper 2024\\8. (I) Data In Brief\\3. Write\\Output'):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    dice_scores = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        img_path = image_paths[i]\n",
    "        mask_path = mask_paths[i]\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = load_img(img_path, target_size=(256, 256))\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        # Load the mask\n",
    "        mask = load_img(mask_path, target_size=(256, 256), color_mode=\"grayscale\")\n",
    "        mask_array = img_to_array(mask) / 255.0\n",
    "\n",
    "        # Make prediction\n",
    "        pred_mask = model.predict(img_array)\n",
    "        pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "        # Create segmented image by overlaying the predicted mask on the input image with transparency\n",
    "        segmented_img = img_array[0].copy()\n",
    "        overlay = np.zeros_like(segmented_img)\n",
    "        overlay[pred_mask[0, :, :, 0] == 1] = [1, 1, 0]  # Yellow color for segmentation\n",
    "\n",
    "        # Combine original image with overlay\n",
    "        alpha = 0.3  # Adjust transparency here\n",
    "        combined_img = (1 - alpha) * segmented_img + alpha * overlay\n",
    "\n",
    "        # Save the segmented image\n",
    "        combined_img_pil = tf.keras.preprocessing.image.array_to_img(combined_img)\n",
    "        combined_img_pil.save(os.path.join(output_dir, f'segmented_img_{i}.png'), dpi=(300, 300))\n",
    "\n",
    "        # Calculate and save the Dice coefficient\n",
    "        dice_score = dice_coefficient(mask_array, pred_mask[0])\n",
    "        dice_scores.append(dice_score)\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.imshow(img_array[0])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"True Mask\")\n",
    "        plt.imshow(mask_array[:, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.imshow(pred_mask[0, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Save each plot to the output directory with a unique name\n",
    "        plot_filename = os.path.join(output_dir, f'output_{i}.png')\n",
    "        plt.savefig(plot_filename, dpi=300)\n",
    "        plt.close()  # Important to close the plot to free up memory\n",
    "\n",
    "    return dice_scores\n",
    "\n",
    "# Example usage, assuming `val_image_paths` and `val_mask_paths` are lists of paths to validation images and masks, and `model` is your trained model.\n",
    "dice_scores = display_predictions(val_image_paths, val_mask_paths, model, num_samples=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
